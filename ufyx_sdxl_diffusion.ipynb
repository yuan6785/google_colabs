{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuan6785/google_colabs/blob/master/ufyx_sdxl_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVJCUT5Md_TB"
      },
      "source": [
        "# 参考 https://zhuanlan.zhihu.com/p/643420260\n",
        "python3.10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 环境配置,自定义魔法命令"
      ],
      "metadata": {
        "id": "ADOkUnYXHAgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yx_magic.py\n",
        "\n",
        "# writefile和yxwritefile的区别是，在colob里面，一个没有语法提示，一个有语法提示------重要----\n",
        "\n",
        "from IPython.core.magic import (\n",
        "    magics_class,\n",
        "    Magics,\n",
        "    line_magic,\n",
        "    cell_magic\n",
        ")\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "@magics_class\n",
        "class MagicOrder(Magics):\n",
        "    \"\"\"\n",
        "    自定义一个类，类名叫什么无所谓\n",
        "    但要继承 Magics，并且要被 magics_class 装饰\n",
        "    \"\"\"\n",
        "\n",
        "    @line_magic\n",
        "    def run_conda_venv1(self, line):\n",
        "        print(1)\n",
        "\n",
        "    @cell_magic\n",
        "    def yxwritefile(self, line, cell):\n",
        "        \"\"\"\n",
        "        重写%%writefile,这样python代码才有格式\n",
        "        \"\"\"\n",
        "        # with open(line, 'w', encoding='utf-8') as f:\n",
        "        with open(line, 'w') as f:\n",
        "            f.write(cell)\n",
        "        print(\"write end--\")\n",
        "\n",
        "def load_ipython_extension(ip):\n",
        "    # 在函数内部，我们将类 MagicOrder 注册进去\n",
        "    # 然后就可以使用它内部的魔法命令了\n",
        "    ip.register_magics(MagicOrder)"
      ],
      "metadata": {
        "id": "khpNSiDrj0al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# sys.path.append(\"/content\")\n",
        "%cd /content\n",
        "%load_ext yx_magic\n",
        "%reload_ext yx_magic"
      ],
      "metadata": {
        "id": "HZ9tb_i_j44G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# json命令解析库, 用于类似conda_root=$(echo \"$file_content\" | jq -r '.conda_root')这样的命令------废弃（仅供参考，执行也不影响）-----\n",
        "# !apt-get install jq\n",
        "# 后面改为了环境变量配置的方式--这个也废弃（仅供参考）"
      ],
      "metadata": {
        "id": "_kUpENt_I_cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 各种shell脚本里面使用的公共变量定义(废弃，仅供参考)----其实这里用%env conda_root=/content;这样更方便----废弃（仅供参考，执行也不影响）-----\n",
        "# %%yxwritefile yx_shell_vars.txt\n",
        "# {\n",
        "#   \"conda_root\":\"/content\",\n",
        "#   \"conda_path\":\"/content/yx_miniconda3\",\n",
        "#   \"my_env_name\":\"sd_python310\",\n",
        "#   \"conda_base_py\":\"3.10\",\n",
        "#   \"ipykernel_name\":\"yxpython310\"\n",
        "# }"
      ],
      "metadata": {
        "id": "RIhZoT-GHMJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置全局环境变量(替换上面的yx_shell_vars.txt的方式--重要---)---注意等号后不要有空格，结束也不要有空格----重要-----\n",
        "# ---\n",
        "# conda的安装包下载路径\n",
        "%env conda_root=/content\n",
        "# conda安装路径\n",
        "%env conda_path=/content/yx_miniconda3\n",
        "# 虚拟环境名称\n",
        "%env my_env_name=sd_python310\n",
        "# 虚拟环境的基础python版本\n",
        "%env conda_base_py=3.10\n",
        "# 调试输出\n",
        "!echo $conda_root  $conda_path $my_env_name  $conda_base_py"
      ],
      "metadata": {
        "id": "VIYwm1qnVEBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi  # 看cuda的版本，方便下面安装pytorch的选择"
      ],
      "metadata": {
        "id": "EXqmdFa80unU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# 运行一次安装conda环境和虚拟python环境--\n",
        "# 运行一次即可，这个会实时输出日志，比%%bash好太多了----\n",
        "# 安装conda并安装虚拟环境\n",
        "cd /content\n",
        "#\n",
        "# file_content=$(cat yx_shell_vars.txt)\n",
        "# conda_root=\"/content/drive/MyDrive/conda_env\"  # 如果需要安装到drive，则可以修改路径\n",
        "# conda_root=$(echo \"$file_content\" | jq -r '.conda_root')  # conda的安装包下载路径\n",
        "# conda_path=$(echo \"$file_content\" | jq -r '.conda_path')  # conda安装路径\n",
        "# my_env_name=$(echo \"$file_content\" | jq -r '.my_env_name')\n",
        "# conda_base_py=$(echo \"$file_content\" | jq -r '.conda_base_py')\n",
        "# ipykernel_name=$(echo \"$file_content\" | jq -r '.ipykernel_name')\n",
        "echo $conda_root  $conda_path $my_env_name  $conda_base_py\n",
        "#\n",
        "echo \"var end---\"\n",
        "wget -nc -P ${conda_root} https://repo.anaconda.com/miniconda/Miniconda3-py38_23.1.0-1-Linux-x86_64.sh\n",
        "cd ${conda_root}&&chmod -Rf 777 Miniconda3-py38_23.1.0-1-Linux-x86_64.sh&&chmod +x Miniconda3-py38_23.1.0-1-Linux-x86_64.sh\n",
        "# -f加上是强制覆盖安装\n",
        "cd ${conda_root}&&bash Miniconda3-py38_23.1.0-1-Linux-x86_64.sh -b -f -p ${conda_path}\n",
        "# 初始化conda\n",
        "eval \"$(${conda_path}/bin/conda shell.bash hook)\"\n",
        "# 创建虚拟环境\n",
        "conda create -y --name ${my_env_name} python=${conda_base_py}\n",
        "# 激活虚拟环境\n",
        "conda activate ${my_env_name}\n",
        "# 开始在虚拟环境安装需要的依赖包，  下面的jupyter和google-colab版本号也可以不带，这样可以支持以后的colab， 这里不要用pip安装，会编译，非常慢\n",
        "# conda install -q -y jupyter  # jupyter==1.0.0\n",
        "# conda install -q -y google-colab -c conda-forge  #  google-colab==1.0.0\n",
        "python -c \"import sys; print(sys.executable)\""
      ],
      "metadata": {
        "id": "70QRNX3FFFSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# 在上面的虚拟环境中安装需要的包\n",
        "cd /content\n",
        "#\n",
        "# file_content=$(cat yx_shell_vars.txt)\n",
        "# conda_root=\"/content/drive/MyDrive/conda_env\"  # 如果需要安装到drive，则可以修改路径\n",
        "# conda_root=$(echo \"$file_content\" | jq -r '.conda_root')  # conda的安装包下载路径\n",
        "# conda_path=$(echo \"$file_content\" | jq -r '.conda_path')  # conda安装路径\n",
        "# my_env_name=$(echo \"$file_content\" | jq -r '.my_env_name')\n",
        "echo $conda_root  $conda_path $my_env_name\n",
        "echo \"var end---\"\n",
        "# 初始化conda\n",
        "eval \"$(${conda_path}/bin/conda shell.bash hook)\"\n",
        "# 激活虚拟环境\n",
        "conda activate ${my_env_name}\n",
        "# 安装sdxl需要的包----只需要环境不要额外安装包的可以去掉这里-----\n",
        "# torch安装参考笔记[pytorch的安装指引]\n",
        "pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "pip install diffusers==0.19.3 transformers==4.27.0 accelerate==0.21.0\n",
        "pip install safetensors==0.3.1 invisible_watermark==0.2.0 tensorrt==8.6.0\n",
        "pip install xformers==0.0.20\n",
        "# 校验\n",
        "python -c \"import torch;print(torch.__version__)\""
      ],
      "metadata": {
        "id": "xIzRR7-Ss1pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 生成脚本"
      ],
      "metadata": {
        "id": "7Ak11AeTHGM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "RJr_NOlU6Dmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%yxwritefile yx_vars.py\n",
        "import torch\n",
        "is_other_vae=False # 是否启用另外的vae\n",
        "base_png=\"/content/base.png\"\n",
        "refiner_png=\"/content/refiner.png\"\n",
        "# 输入提示词\n",
        "prompt = \"\"\"A dreamy painting, The painting style is more dreamy and bright, there are several children playing\n",
        "   football on the dreamy football field, the football field is next to the sea, there are sailboats\n",
        "   drifting in the sea, and the sky is dreamy blue\"\"\"\n",
        "# 输入负向提示词，表示我们不想要生成的特征\n",
        "negative_prompt = \"many children, many people, (Mountain)\"\n",
        "# 设置seed，可以固定构图\n",
        "seed = torch.Generator(\"cuda\").manual_seed(42)\n",
        "\n"
      ],
      "metadata": {
        "id": "93yXOrN5FpqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76-I0oZmnRRz"
      },
      "outputs": [],
      "source": [
        "%%yxwritefile yx_sdxl_base.py\n",
        "# writefile和yxwritefile的区别是，在colob里面，一个没有语法提示，一个有语法提示------重要\n",
        "# 加载diffusers和torch依赖库\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers.models import AutoencoderKL\n",
        "import torch\n",
        "from yx_vars import prompt, negative_prompt, seed, base_png, refiner_png, is_other_vae\n",
        "\n",
        "\n",
        "\n",
        "if is_other_vae:\n",
        "  # vae\n",
        "  vae = AutoencoderKL.from_pretrained(\"stabilityai/sdxl-vae\",  torch_dtype=torch.float16)\n",
        "  # vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "  # 构建Stable Diffusion XL Base模型的Pipeline，加载Stable Diffusion XL Base模型\n",
        "  pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",torch_dtype=torch.float16,\n",
        "                                            variant=\"fp16\" ,vae=vae, use_safetensors=True)\n",
        "else:\n",
        "  pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",torch_dtype=torch.float16,\n",
        "                                            variant=\"fp16\", use_safetensors=True)\n",
        "# \"本地路径/stable-diffusion-xl-base-0.9\"表示我们需要加载的Stable Diffusion XL Base模型，\n",
        "# 大家可以关注Rocky的公众号WeThinkIn，后台回复：SDXL模型，即可获得资源链接\n",
        "# \"fp16\"代表启动fp16精度。比起fp32，fp16可以使模型显存占用减半。\n",
        "\n",
        "\n",
        "# 使用GPU进行Pipeline的推理\n",
        "pipe.to(\"cuda\")\n",
        "# 参考:\n",
        "# https://huggingface.co/docs/diffusers/optimization/fp16#memory-efficient-attention\n",
        "# 不用xformer的方式 https://huggingface.co/docs/diffusers/optimization/torch2.0\n",
        "# pipe.enable_xformers_memory_efficient_attention()  # pytorch2.0默认已经支持了\n",
        "print(11111, prompt)\n",
        "# Pipeline进行推理\n",
        "# image = pipe(prompt, negative_prompt=negative_prompt,generator=seed).images[0]\n",
        "image = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=20).images[0]\n",
        "# Pipeline生成的images包含在一个list中：[<PIL.Image.Image image mode=RGB size=1024x1024>]\n",
        "#所以需要使用images[0]来获取list中的PIL图像\n",
        "#\n",
        "# 保存生成图像\n",
        "image.save(base_png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%yxwritefile yx_sdxl_refiner.py\n",
        "# writefile和yxwritefile的区别是，在colob里面，一个没有语法提示，一个有语法提示------重要\n",
        "# 加载diffusers和torch依赖库\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers.models import AutoencoderKL\n",
        "from diffusers.utils import load_image\n",
        "import torch\n",
        "from yx_vars import prompt, negative_prompt, seed, base_png, refiner_png, is_other_vae\n",
        "\n",
        "if is_other_vae:\n",
        "  # vae\n",
        "  vae = AutoencoderKL.from_pretrained(\"stabilityai/sdxl-vae\", torch_dtype=torch.float16)\n",
        "  # vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "  # 构建Stable Diffusion XL Base模型的Pipeline，加载Stable Diffusion XL Refiner模型\n",
        "  pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "                                          torch_dtype=torch.float16, variant=\"fp16\",\n",
        "                                          vae=vae, use_safetensors=True)\n",
        "else:\n",
        "  pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "                                          torch_dtype=torch.float16, variant=\"fp16\",\n",
        "                                          use_safetensors=True)\n",
        "\n",
        "# 使用GPU进行Pipeline的推理\n",
        "pipe.to(\"cuda\")\n",
        "# 参考:\n",
        "# https://huggingface.co/docs/diffusers/optimization/fp16#memory-efficient-attention\n",
        "# 不用xformer的方式 https://huggingface.co/docs/diffusers/optimization/torch2.0\n",
        "# pipe.enable_xformers_memory_efficient_attention()  # pytorch2.0默认已经支持了\n",
        "#\n",
        "init_image = load_image(base_png).convert(\"RGB\")\n",
        "# Pipeline进行推理\n",
        "# image = pipe(prompt, negative_prompt=negative_prompt,generator=seed, image=init_image).images[0]\n",
        "image = pipe(prompt, negative_prompt=negative_prompt, image=init_image, num_inference_steps=15).images[0]\n",
        "# Pipeline生成的images包含在一个list中：[<PIL.Image.Image image mode=RGB size=1024x1024>]\n",
        "#所以需要使用images[0]来获取list中的PIL图像\n",
        "\n",
        "# 保存生成图像\n",
        "image.save(refiner_png)"
      ],
      "metadata": {
        "id": "fljJAY15D7bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%yxwritefile yx_sdxl_both.py\n",
        "\"\"\"\n",
        "参考\n",
        "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\n",
        "但是在默认的colab上面，gpu和内存都不够，跑步起来合并的\n",
        "\"\"\"\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "from yx_vars import prompt, negative_prompt, seed, base_png, refiner_png, is_other_vae\n",
        "\n",
        "# load both base & refiner\n",
        "base = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
        ")\n",
        "# base.to(\"cuda\")\n",
        "# 显存不够，只有加这句，去掉.to(\"cuda\"), 这个并不是全程cpu计算，只是在gpu不够的情况下，cpu会辅助，实现在低vram下的使用\n",
        "base.enable_model_cpu_offload()\n",
        "#base.enable_xformers_memory_efficient_attention()\n",
        "refiner = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "    text_encoder_2=base.text_encoder_2,\n",
        "    vae=base.vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        ")\n",
        "# refiner.to(\"cuda\")\n",
        "# 显存不够，只有加这句，去掉.to(\"cuda\"), 这个并不是全程cpu计算，只是在gpu不够的情况下，cpu会辅助，实现在低vram下的使用\n",
        "refiner.enable_model_cpu_offload()\n",
        "#refiner.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# Define how many steps and what % of steps to be run on each experts (80/20) here\n",
        "n_steps = 40\n",
        "high_noise_frac = 0.8\n",
        "\n",
        "# prompt = \"A majestic lion jumping from a big stone at night\"\n",
        "\n",
        "# run both experts\n",
        "image = base(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=n_steps,\n",
        "    denoising_end=high_noise_frac,\n",
        "    output_type=\"latent\",\n",
        ").images\n",
        "image = refiner(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=n_steps,\n",
        "    denoising_start=high_noise_frac,\n",
        "    image=image,\n",
        ").images[0]\n",
        "# 保存生成图像\n",
        "image.save(refiner_png)"
      ],
      "metadata": {
        "id": "VEGe-R039qtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 开始生成"
      ],
      "metadata": {
        "id": "4pxEFv1eBzl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# base和refiner单独执行，GPU可以得到有效释放\n",
        "cd /content\n",
        "# file_content=$(cat yx_shell_vars.txt)\n",
        "# conda_root=\"/content/drive/MyDrive/conda_env\"  # 如果需要安装到drive，则可以修改路径\n",
        "# conda_root=$(echo \"$file_content\" | jq -r '.conda_root')  # conda的安装包下载路径\n",
        "# conda_path=$(echo \"$file_content\" | jq -r '.conda_path')  # conda安装路径\n",
        "# my_env_name=$(echo \"$file_content\" | jq -r '.my_env_name')\n",
        "echo $conda_root  $conda_path $my_env_name\n",
        "echo \"var end---\"\n",
        "eval \"$(${conda_path}/bin/conda shell.bash hook)\"\n",
        "conda activate ${my_env_name}\n",
        "#\n",
        "VAR1=$(dirname $(python -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\"))\n",
        "VAR2=$(dirname $(python -c \"import tensorrt;print(tensorrt.__file__)\"))\n",
        "echo $VAR1\n",
        "echo $VAR2\n",
        "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/x86_64-linux-gnu:$VAR1:$VAR2\n",
        "echo $LD_LIBRARY_PATH\n",
        "#\n",
        "# echo \"base和refiner一起生成（显存不够---只能启用cpu协助: enable_model_cpu_offload, 但这样内存又不够）:----\"\n",
        "# python -u yx_sdxl_both.py\n",
        "#\n",
        "echo \"base和refiner分开生成(显存足够，内存也足够):----\"\n",
        "python yx_sdxl_base.py\n",
        "python yx_sdxl_refiner.py\n",
        "# end"
      ],
      "metadata": {
        "id": "5UjIX-PP55DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "用默认的python环境进行ui交互以及展示\n",
        "\"\"\"\n",
        "import time\n",
        "time.sleep(3)\n",
        "%cd /content\n",
        "from yx_vars import refiner_png\n",
        "from PIL import Image\n",
        "img = Image.open(refiner_png)\n",
        "img"
      ],
      "metadata": {
        "id": "G9GaTNqOBxDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 其他调试工具\n"
      ],
      "metadata": {
        "id": "xYy85vjjB4N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env YXHAHA=/bin/bash\n",
        "!echo $YXHAHA\n",
        "!echo $SHELL  # 查看默认的shell是什么， 即%%shell用的什么"
      ],
      "metadata": {
        "id": "UXLovDjW2MmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "重启运行时\n",
        "\"\"\"\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "V-GIK6m1FJcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ADOkUnYXHAgl",
        "7Ak11AeTHGM1",
        "4pxEFv1eBzl6",
        "xYy85vjjB4N5"
      ],
      "authorship_tag": "ABX9TyNPW+1YjkxKz9euI40o6DkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}